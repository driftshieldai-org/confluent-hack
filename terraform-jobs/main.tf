resource "google_storage_bucket_object" "template" {
  bucket = var.bucket_name
  name   = "dataflow/template/realtime_stream_anomaly.json"
  source = "${path.module}/../dataflow/template/realtime_stream_anomaly.json"
}

resource "google_dataflow_flex_template_job" "job" {
  provider                = google-beta
  name                    = "driftshieldai-df-job-${formatdate("YYYYMMDD-hhmm", timestamp())}"

  lifecycle {
    ignore_changes = [name,temp_location,staging_location,machine_type]
  }

  region                  = var.region
  project                 = var.project_id
  container_spec_gcs_path = "gs://${var.bucket_name}/dataflow/template/realtime_stream_anomaly.json"
  temp_location           = "gs://${var.bucket_name}/dataflow/temp"
  staging_location        = "gs://${var.bucket_name}/dataflow/staging"

  parameters = {
    bootstrap_servers=var.bootstrap_servers,
    kafka_topic = var.kafka_topic,
    output_table = var.stream_table,
    model_dir = "gs://${var.bucket_name}/models",
    anomaly_output_table = var.anomaly_table,
    summary_output_table = var.anomaly_summ_table,
    api_project = var.project_id,
    api_region=var.region
  }
  enable_streaming_engine = true

  # Optional overrides
  max_workers             =  1
  machine_type            =  "n1-standard-1"
  ip_configuration        = "WORKER_IP_PUBLIC"
  service_account_email   = var.service_account_id
  on_delete               = "cancel"
  network                 = "projects/${var.project_id}/networks/${var.vpc_network}"
  subnetwork              = "regions/${var.region}/subnetworks/${var.subnet_name}"

 depends_on = [ google_storage_bucket_object.template]
}

resource "google_cloud_run_v2_service" "anomaly-ui" {
  name     = var.cloudrun_name
  location = var.region
  project = var.project_id
  ingress = "INGRESS_TRAFFIC_ALL"


  template {
    containers {
      image = "us-central1-docker.pkg.dev/${var.project_id}/${var.repo_name}/${var.ui_image_name}:latest"
      resources {
        limits = {
          cpu    = 1
          memory = "512Mi"
        }
      }
    }  
    scaling {
        max_instance_count = 1
        min_instance_count = 0
      }  
    
    
    service_account = var.service_account_id 
  }
  
}

resource "google_cloud_run_v2_service_iam_member" "public_access" {
  project  = google_cloud_run_v2_service.anomaly-ui.project
  location = google_cloud_run_v2_service.anomaly-ui.location
  name     = google_cloud_run_v2_service.anomaly-ui.name
  role     = "roles/run.invoker"
  member   = "allUsers"
}


# 1. log-based metric to count anomaly summary logs.
# This metric will count every log entry where jsonPayload.identifier is "anomaly_summary".
resource "google_logging_metric" "anomaly_summary_count" {
  project = var.project_id
  name    = "anomaly-summary-count"
  description = "Counts the number of anomaly summaries generated by the Dataflow pipeline."
  
  # This filter targets the specific structured logs  created.
  # It looks for logs from Dataflow steps that have the correct identifier in their JSON payload.
  filter = <<-EOT
   # resource.type="dataflow_step"
    jsonPayload.identifier="anomaly_summary"
  EOT

  metric_descriptor {
    metric_kind = "DELTA"
    value_type  = "INT64"
    unit        = "1"
    labels {
      key         = "anomaly_count"
      value_type  = "INT64"
      description = "The number of raw anomalies included in the summary."
    }
  }

  label_extractors = {
    # This extracts the 'anomaly_count' from the log's JSON payload and makes it a metric label.
    "anomaly_count" = "EXTRACT(jsonPayload.anomaly_count)"
  }
}

# 2. Create a notification channel to send alerts to.
# This example uses email, but you can also use Slack, PagerDuty, etc.
resource "google_monitoring_notification_channel" "email_channel" {
  project      = var.project_id
  display_name = "Dataflow Anomaly Alerts"
  type         = "email"
  
  labels = {
    # Replace with the email address or distribution list for notifications.
    email_address = "driftshieldai@gmail.com" 
  }
}

# 3. Create the alert policy that uses the log-based metric and notification channel.
resource "google_monitoring_alert_policy" "anomaly_summary_alert" {
  project      = var.project_id
  display_name = "New Anomaly Summary Detected in Dataflow"
  combiner     = "OR"

  conditions {
    display_name = "A new anomaly summary log was detected"

    condition_threshold {
      # This filter points to the log-based metric we created above.
     # filter = "metric.type=\"logging.googleapis.com/user/${google_logging_metric.anomaly_summary_count.name}\" AND resource.type=\"dataflow_step\""
       filter = "metric.type=\"logging.googleapis.com/user/${google_logging_metric.anomaly_summary_count.name}\" AND resource.type=\"cloud_run_revision\""      
      # This condition will trigger if the count is greater than 0 over a 5-minute period.
      # This means an alert will fire for each summary generated.
      comparison      = "COMPARISON_GT"
      threshold_value = 0
      duration        = "60s" # 1 minutes

      trigger {
        count = 1
      }
    }
  }

  # Attach the email notification channel to this policy.
  notification_channels = [
    google_monitoring_notification_channel.email_channel.id,
  ]

  # Documentation that will be included in the alert notification.
  # This helps the person receiving the alert understand what's happening.
  
  documentation {
    content   = <<-EOT
      ## Anomaly Summary Detected
      A new set of anomalies has been summarized by the real-time Dataflow pipeline.
      
      Summary from Gemini:
      $${log.extracted_label.summary}

      Number of Anomalies:
      $${log.extracted_label.anomaly_count}

      Action:
      Please review the summary and check the 'real_time_anomalies' and 'gemini_summaries' BigQuery tables for more details.
    EOT
    mime_type = "text/markdown"
  }
  user_labels = {
    "service"    = "dataflow-anomaly-detection",
    "created-by" = "terraform"
  }
}


